<html>
  <head>
    <title>AIna</title>
    <link rel="icon" type="image/png" href="assets/Picture1.png" />

    <meta
      name="description"
      content="Interactive visualiser for the Google Cloud Video Intelligence API."
    />
    <meta
      name="keywords"
      content="google cloud, video, intelligence, api, video intelligence api, google cloud"
    />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/icon?family=Material+Icons"
    />
    <link
      rel="stylesheet"
      href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css"
    />
    <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>

    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
    <script src="https://unpkg.com/vue-router@2.0.0/dist/vue-router.js"></script>

    <!-- 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-N80GH8KX9W"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-N80GH8KX9W', { client_storage: 'none' });

    </script> -->

    <style>
      body {
          color:white;
          text-align: center;
          min-height: 1500px;
          min-width: 1130px;
          background-color:black;
          background-size:cover;

      }

      h1, h2, h3, h4, h5 {
        color: rgb(84, 47, 253);
      }

      #video-conatiner {
          position: relative;
          width: 800px;
          margin: 15px;
          display: inline-block;
          box-shadow: 0 4px 20px rgb(84, 47, 253);
          border-radius: 8px;
      }

      #video-conatiner>canvas {
          width: 100%;
          position: absolute;
          opacity: 0.8;
          left: 0;
          height: 100%;
          pointer-events: none;
          box-shadow: 0 4px 20px rgb(84, 47, 253);
          border-radius: 8px;
      }

      video {
          width: 100%;
          margin: auto;
          display: block;
      }

      video::-webkit-media-controls-fullscreen-button {
          display: none !important;
      }

      .upload-area {
        color:aliceblue;
        /* display: inline-block; */
        width: 200px;
        /* height: 62px; */
        border: dashed #ededed 3px;
        border-radius: 5px;
        padding: 15px;
        margin: 15px;
        overflow: hidden;
    }

      .mdl-layout__header {
          background-color: transparent;
          color: #e0e0e0;
          font-weight: 900;
          text-shadow: 1px 1px 2px rgba(0,0,0,0.5);
          padding-left: 40%;
      }

      #upload-data {
          display: inline-block;
          text-align: center;
          vertical-align: top;
          width: 250px;
      }

      #upload-data>p {
          text-align: justify;
      }

      .feature-tabs {
          margin: 30px;
          text-align: center;
      }

      .feature-tabs>div {
          display: inline-block;
          font-size: 1.2em;
          padding: 12px;
          cursor: pointer;
          color: #777777;
          font-weight: 300;

          border: solid #4285f4 1px;
          border-radius: 5px;
          margin: 5px;
      }

      .feature-tabs>div:hover {
          background-color: #4285f41a;
      }


      .feature-tabs>.selected {
          border-bottom: 2px solid #4285F4;
      }

      .feature-tabs>.disabled {
          color: #cdcdcd;
      }

      .logo {
          width: inherit;
      }


      .data-warning {
          background-color: #ffffc3;
          /* display: inline-block; */
          margin: auto;
          position: relative;
          padding: 15px;
          text-align: center;
      }

      .material-icons {
          vertical-align: middle;
          font-size: 19px;
      }

      .nav-tab>.material-icons {
          color: #0F9D58;
      }

      .search-container {
          margin: 20px;
          text-align: center;
      }

      .search-input-container {
          display: flex;
          justify-content: center;
          align-items: center;
      }

      .search-container input {
          width: 300px;
          padding: 5px;
          font-size: 16px;
          margin-right: 10px;
      }

      .search-button {
          padding: 5px 10px;
          font-size: 16px;
          background-color: #4285F4;
          color: white;
          border: none;
          cursor: pointer;
      }

      .search-button:hover {
          background-color: #3367D6;
      }

      .search-results {
          margin-top: 10px;
          max-height: 200px;
          overflow-y: auto;
          border: 1px solid #ccc;
          border-radius: 5px;
      }

      .search-result {
          padding: 5px;
          cursor: pointer;
          display: flex;
          justify-content: space-between;
      }

      .search-result:hover {
          background-color: #f0f0f0;
      }
      canvas {
          position: fixed;
          inset: 0;
          pointer-events: none;
          z-index: 0;
        }

      /* Add custom animations and chat styles */
      .search-result:hover {
          background-color: #f0f0f0;
      }
      canvas {
          position: fixed;
          inset: 0;
          pointer-events: none;
          z-index: 0;
      }
      
      /* Custom scrollbar for chat */
      .scrollbar-thin::-webkit-scrollbar {
          width: 4px;
      }
      
      .scrollbar-thumb-blue-500::-webkit-scrollbar-thumb {
          background-color: rgba(59, 130, 246, 0.5);
          border-radius: 10px;
      }
      
      .scrollbar-track-blue-900\/30::-webkit-scrollbar-track {
          background-color: rgba(30, 58, 138, 0.2);
      }
      
      /* Animation for chat messages */
      @keyframes fadeIn {
          from {
              opacity: 0;
              transform: translateY(10px);
          }
          to {
              opacity: 1;
              transform: translateY(0);
          }
      }
      
      .animate-fadeIn {
          animation: fadeIn 0.3s ease-out forwards;
      }
      
      /* Chat container styling */
      #chat-bot-container {
          transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
          backdrop-filter: blur(12px);
          z-index: 9999 !important;
          position: fixed !important;
          bottom: 30px !important;
          right: 30px !important;
          will-change: transform;
          filter: drop-shadow(0 4px 20px rgba(59, 130, 246, 0.5));
      }
      
      /* Add spacing to chat content area */
      .chat-content-area {
          padding-top: 10px;
          padding-bottom: 10px;
      }
      
      /* Speech bubble effect for chat messages */
      .message-bubble-user {
          position: relative;
      }
      
      .message-bubble-user::after {
          content: '';
          position: absolute;
          bottom: 0;
          right: -8px;
          width: 0;
          height: 0;
          border: 8px solid transparent;
          border-top-color: #3b82f6;
          border-bottom: 0;
          margin-left: -8px;
          margin-bottom: -8px;
      }

      /* Add bot message bubble and resize handle style */
      /* Speech bubble effect for chat messages */
      .message-bubble-user {
          position: relative;
      }
      
      .message-bubble-user::after {
          content: '';
          position: absolute;
          bottom: 0;
          right: -8px;
          width: 0;
          height: 0;
          border: 8px solid transparent;
          border-top-color: #3b82f6;
          border-bottom: 0;
          margin-left: -8px;
          margin-bottom: -8px;
      }
      
      .message-bubble-bot {
          position: relative;
      }
      
      .message-bubble-bot::after {
          content: '';
          position: absolute;
          bottom: 0;
          left: -8px;
          width: 0;
          height: 0;
          border: 8px solid transparent;
          border-top-color: #374151;
          border-bottom: 0;
          margin-left: -8px;
          margin-bottom: -8px;
      }
      
      /* Resize handle */
      .resize-handle {
          position: absolute;
          bottom: 0;
          right: 0;
          width: 15px;
          height: 15px;
          cursor: nwse-resize;
          border-right: 3px solid rgba(59, 130, 246, 0.5);
          border-bottom: 3px solid rgba(59, 130, 246, 0.5);
          border-bottom-right-radius: 0.5rem;
          opacity: 0.6;
          transition: opacity 0.2s;
      }
      
      .resize-handle:hover {
          opacity: 1;
      }
    </style>
  </head>

  <body>
    <div id="app" class="mdl-layout--fixed-header">
      <canvas id="particleCanvas"></canvas>
      <header class="relative mb-14">
        <!-- Background Image Layer with Blur -->
        <div
          class="absolute inset-0 bg-[url('assets/header-bg.jpg')] bg-cover bg-center backdrop-blur-md opacity-60 z-0"
        ></div>
      
        <!-- Header Content -->
        <div class="relative z-10 bg-gray-900/70 px-6 py-4 shadow-xl border-b border-blue-900">
          <div class="container mx-auto flex items-center justify-between">
            <!-- Logo and Brand Name -->
            <div class="flex items-center space-x-3">
              <img src="assets/Picture1.png" alt="Logo" class="h-12 w-auto" />
            </div>
            <span class="text-3xl font-bold text-blue-400">AIna</span>
          </div>
        </div>
      </header>
      <div class="text-center mx-auto mb-4 px-4 font-extrabold">
        <h5 class="text-3xl md:text-4xl font-extrabold mb-4 text-blue-300 leading-snug">
          Unlock the Power of Video with AI
        </h5>
        
        <p class="text-lg md:text-xl text-blue-200 leading-relaxed">
          Annotate Video using this script right
          <a
            target="_blank"
            href="https://colab.research.google.com/drive/18atVgKfkiGSTuZgTS2G27GMqmkwNmsRr?usp=sharing"
            class="text-blue-400 underline hover:text-blue-300 transition font-semibold"
          >
            here
          </a>
          if you want to run all features at once.
        </p>
      </div>
      <div id="video-conatiner">
        <canvas id="my_canvas" width="800" height="500"></canvas>
        <video id="video" controls autoplay></video>
      </div>

      <div 
  id="upload-data" 
  class="flex flex-col md:flex-row gap-8 justify-center items-center mt-16 w-full max-w-4xl mx-auto px-4"
>
  <!-- Video Upload -->
  <label
    for="video_input"
    class="upload-area w-full md:w-80 h-48 flex flex-col justify-center items-center border-2 border-dashed border-gray-400 rounded-lg p-6 text-white bg-black/30 hover:bg-black/40 hover:border-blue-500 transition-all cursor-pointer relative overflow-hidden group"
    ondrop="drop_video(event)"
    ondragover="dragOver(event)"
    ondragleave="dragLeave(event)"
  >
    <div class="absolute inset-0 bg-blue-500/10 scale-y-0 group-hover:scale-y-100 transition-transform origin-bottom"></div>
    <svg class="w-12 h-12 text-gray-300 mb-3" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 4v16M17 4v16M3 8h18M3 16h18"></path>
    </svg>
    <p class="text-base font-medium mb-2 relative z-10">Upload Your Video</p>
    <input id="video_input" type="file" accept="video/*" class="hidden" />
    <span class="text-sm text-gray-300 relative z-10">Drop file here or click to browse</span>
    <span class="text-xs text-gray-400 mt-2 relative z-10">MP4, WebM, AVI, MOV, etc.</span>
    <div id="video_preview" class="mt-2 hidden"></div>
  </label>
  
  <!-- JSON Upload -->
  <label
    for="json_input"
    class="upload-area w-full md:w-80 h-48 flex flex-col justify-center items-center border-2 mt-4 border-dashed border-gray-400 rounded-lg p-6 text-white bg-black/30 hover:bg-black/40 hover:border-blue-500 transition-all cursor-pointer relative overflow-hidden group"
    ondrop="drop_json(event)"
    ondragover="dragOver(event)"
    ondragleave="dragLeave(event)"
  >
    <div class="absolute inset-0 bg-blue-500/10 scale-y-0 group-hover:scale-y-100 transition-transform origin-bottom"></div>
    <svg class="w-12 h-12 text-gray-300 mb-3" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
    </svg>
    <p class="text-base font-medium mb-2 relative z-10">Upload Your .JSON</p>
    <input id="json_input" type="file" accept="application/JSON" class="hidden" />
    <span class="text-sm text-gray-300 relative z-10">Drop file here or click to browse</span>
    <span class="text-xs text-gray-400 mt-2 relative z-10">Metadata or Config Files</span>
    <div id="json_preview" class="mt-2 hidden"></div>
  </label>
</div>


    <div
    v-if="data_misaligned"
    class="data-warning bg-blue-100 border-l-4 border-blue-500 text-blue-700 p-4 rounded-md shadow-sm max-w-xl mx-auto mt-4"
    >
    <p class="font-semibold">Data Misalignment Detected</p>
    <p class="text-sm">
    It looks like the JSON data doesn't align with the video file. Are you sure
    you've uploaded the correct files?
    </p>
    </div>

      <annotations-nav
        v-bind:title_ids_dict="title_ids_dict"
        v-bind:detected_features="detected_features"
        v-bind:current_view="current_view"
        v-on:nav-clicked="set_current_view"
      >
      </annotations-nav>

      <object-tracking-viz
        v-if="current_view == 'Object Tracking'"
        id="object_tracks"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      ></object-tracking-viz>

      <label-detection-viz
        v-if="current_view == 'Label Detection'"
        id="label_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      ></label-detection-viz>

      <shot-detection-viz
        v-if="current_view == 'Shot Detection'"
        id="shot_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:shot-clicked="jump_video"
      ></shot-detection-viz>

      <speech-transcription-viz
        v-if="current_view == 'Speech Transcription'"
        id="speech_transcription"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:word-clicked="jump_video"
      >
      </speech-transcription-viz>

      <person-detection-viz
        v-if="current_view == 'Person Detection'"
        id="person_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </person-detection-viz>

      <face-detection-viz
        v-if="current_view == 'Face Detection'"
        id="face_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </face-detection-viz>

      <logo-recognition-viz
        v-if="current_view == 'Logo Recognition'"
        id="logo_recognition"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </logo-recognition-viz>

      <text-detection-viz
        v-if="current_view == 'Text Detection'"
        id="text_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </text-detection-viz>

      <explicit-content-detection-viz
        v-if="current_view == 'Explicit Content Detection'"
        id="explicit_content_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:shot-clicked="jump_video"
      >
      </explicit-content-detection-viz>

      <search-component
        v-bind:json_data="json_data"
        v-on:jump-to-time="jump_video"
      ></search-component>
      
      <!-- Chat Bot Window (Fixed Position with Resize) -->
      <div id="chat-bot-container" 
           class="fixed bottom-5 right-5 z-[1000] overflow-hidden transition-all duration-300 rounded-lg shadow-2xl border-2 border-blue-500 relative"
           :style="{
             width: chatOpen ? chatWidth + 'px' : '320px',
             height: chatOpen ? chatHeight + 'px' : '40px',
             background: 'linear-gradient(to bottom, #1e293b, #111827)',
             boxShadow: chatOpen ? '0 20px 40px -10px rgba(59, 130, 246, 0.6)' : '0 10px 25px -5px rgba(59, 130, 246, 0.4)'
           }">
        <!-- Resize handle in bottom-right corner -->
        <div v-if="chatOpen" @mousedown.stop="startResize" class="resize-handle"></div>
        <!-- Chat Header - Normal Size -->
        <div class="bg-gradient-to-r from-blue-700 to-blue-600 px-3 py-2 flex justify-between items-center cursor-pointer rounded-t-lg"
             @click="toggleChat">
          <div class="flex items-center">
            <div class="relative">
              <img src="assets/Picture1.png" alt="AIna Bot" class="h-6 w-6 mr-2 filter drop-shadow-md">
              <div class="absolute bottom-0 right-0 w-2 h-2 bg-green-400 rounded-full border border-white"></div>
            </div>
            <h3 class="text-white font-semibold font-sans text-base truncate max-w-[160px]">AIna Assistant</h3>
          </div>
          <div class="flex items-center">
            <!-- Minimize/Maximize button - Normal size -->
            <button class="text-white focus:outline-none hover:bg-blue-500 rounded-md transition-colors px-2" 
                   @click.stop="toggleChat">
              <span v-if="chatOpen" class="material-icons text-sm">expand_more</span>
              <span v-else class="material-icons text-sm">expand_less</span>
            </button>
          </div>
        </div>
        
        <!-- Chat Messages Container with Enhanced Styling and Added Padding -->
        <div v-if="chatOpen" 
            class="overflow-y-auto font-sans scrollbar-thin scrollbar-thumb-blue-500 scrollbar-track-blue-900/30 pt-4 pb-4 chat-content-area" 
            ref="chatMessages" 
            :style="{ height: (chatHeight - 96) + 'px', background: 'linear-gradient(to bottom, #1e293b, #111827)' }">
          <!-- Welcome Message when empty -->
          <div v-if="chatMessages.length === 1" class="text-center p-4 mt-4 text-gray-400 italic text-sm">
            Ask questions about the video content
          </div>
          
          <!-- Message Bubbles with Speech Bubble Effect and Improved Spacing -->
          <div v-for="(message, index) in chatMessages" :key="index" 
               :class="{'flex justify-end': message.sender === 'user', 'flex justify-start': message.sender === 'bot'}"
               class="p-3 pb-4 mb-1 animate-fadeIn">
            <div :class="{
                  'bg-gradient-to-r from-blue-600 to-blue-500 text-white message-bubble-user': message.sender === 'user', 
                  'bg-gradient-to-br from-gray-700 to-gray-800 text-gray-100 message-bubble-bot': message.sender === 'bot',
                  'max-w-xs': !message.text.includes('Scene') && !message.text.includes('detect'),
                  'max-w-md': message.text.includes('Scene') || message.text.includes('detect')
                }" 
                class="rounded-2xl px-4 py-3 shadow-lg border border-transparent hover:border-blue-500/30 backdrop-blur-sm transition-all duration-300">
              <div class="flex items-center mb-1">
                <div v-if="message.sender === 'bot'" class="w-5 h-5 rounded-full overflow-hidden mr-1 border border-blue-300/30">
                  <img src="assets/Picture1.png" alt="AIna" class="w-full h-full object-cover">
                </div>
                <p v-if="message.sender === 'bot'" class="text-xs text-blue-300 font-semibold">AIna</p>
                <p v-else class="text-xs text-blue-200 font-semibold">You</p>
              </div>
              <div class="text-sm leading-relaxed font-sans whitespace-pre-line" v-html="formatMessage(message.text)"></div>
            </div>
          </div>
          
          <!-- Loading Indicator -->
          <div v-if="isLoading" class="flex justify-start p-3">
            <div class="bg-gradient-to-br from-gray-700 to-gray-800 text-gray-100 rounded-2xl px-4 py-3 shadow-lg border border-gray-700/50">
              <div class="flex items-center mb-1">
                <div class="w-5 h-5 rounded-full overflow-hidden mr-1 border border-blue-300/30">
                  <img src="assets/Picture1.png" alt="AIna" class="w-full h-full object-cover">
                </div>
                <p class="text-xs text-blue-300 font-semibold">AIna</p>
              </div>
              <div class="flex space-x-2 items-center">
                <div class="w-2 h-2 bg-blue-400 rounded-full animate-bounce"></div>
                <div class="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style="animation-delay: 0.2s"></div>
                <div class="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style="animation-delay: 0.4s"></div>
              </div>
            </div>
          </div>
        </div>
        
        <!-- Enhanced Chat Input with Animation -->
        <div v-if="chatOpen" class="bg-gradient-to-r from-gray-800 to-gray-900 p-4 border-t border-blue-900/50 rounded-b-lg">
          <div class="flex items-center shadow-lg rounded-full overflow-hidden bg-gray-900 border border-blue-500/30 hover:border-blue-500/70 transition-colors p-1">
            <input 
              id="chat-input-field"
              type="text" 
              v-model="userInput" 
              @keyup.enter="sendMessage"
              placeholder="Ask about the video..." 
              class="flex-1 bg-transparent text-white px-3 py-2 focus:outline-none font-sans text-sm placeholder-gray-500"
            >
            <button 
              @click="sendMessage" 
              class="bg-blue-600 text-white p-2 rounded-full hover:bg-blue-700 focus:outline-none transition-colors"
              :class="{'opacity-50': !userInput.trim(), 'opacity-100': userInput.trim()}"
              :disabled="!userInput.trim()"
            >
              <span class="material-icons text-lg">send</span>
            </button>
          </div>
        </div>
      </div>
    </div>

    <script src="utils/utils.js"></script>

    <script src="components/object_tracking.js"></script>
    <script src="components/label_detection.js"></script>
    <script src="components/shot_detection.js"></script>
    <script src="components/speech_transcription.js"></script>
    <script src="components/person_detection.js"></script>
    <script src="components/face_detection.js"></script>
    <script src="components/logo_recognition.js"></script>
    <script src="components/text_detection.js"></script>
    <script src="components/explicit_content_detection.js"></script>
    <script src="components/search.js"></script>

    <script>
      function jump_video(time) {
        const video = document.querySelector("video");
        video.currentTime = time;
        video.play();
      }

      // define component
      Vue.component("annotations-nav-tab", {
        props: ["title", "current_view", "data_id", "detected_features"],
        computed: {
          has_data: function () {
            return this.detected_features.includes(this.data_id);
          },
        },
        template: `
            <div class="nav-tab" v-bind:class="{selected:current_view == title, disabled:(!has_data)}">{{title}}
                <span v-if="has_data" class="material-icons">
                    check_circle
                </span>
            </div>
            `,
      });

      Vue.component("annotations-nav", {
        props: ["title_ids_dict", "current_view", "detected_features"],
        methods: {
          nav_clicked: function (title) {
            this.$emit("nav-clicked", title);
          },
        },
        template: `
            <div class="feature-tabs">
                <annotations-nav-tab v-for="id, title in title_ids_dict"
                    v-bind:title="title" v-bind:data_id="id"
                    v-bind:detected_features="detected_features" v-bind:current_view="current_view"
                    v-on:click.native="nav_clicked(title)">
                </annotations-nav-tab>
            </div>
            `,
      });

      var router = new VueRouter({
        mode: "history",
        // routes: { path: '/match/:id', component: test_com}
      });

      var app = new Vue({
        router,
        el: "#app",
        data: {
          json_data: {},
          video_info: { width: 800, height: 500, length: 252 },
          video_length: 252,
          current_view: "Label Detection",
          title_ids_dict: {
            "Label Detection": "shot_label_annotations",
            "Shot Detection": "shot_annotations",
            "Object Tracking": "object_annotations",
            "Person Detection": "person_detection_annotations",
            "Face Detection": "face_detection_annotations",
            "Logo Recognition": "logo_recognition_annotations",
            "Speech Transcription": "speech_transcriptions",
            "Text Detection": "text_annotations",
            "Explicit Content Detection": "explicit_annotation",
          },
          // Chat bot related data
          chatOpen: false,
          chatMessages: [
            {
              sender: 'bot',
              text: 'Hello! I can help answer questions about this video. What would you like to know?'
            }
          ],
          userInput: '',
          isLoading: false,
          // Chat window size
          chatWidth: 320,
          chatHeight: 420,
          isResizing: false,
          initialX: 0,
          initialY: 0,
          initialWidth: 320,
          initialHeight: 420
        },
        methods: {
          jump_video: function (event_data) {
            document
              .querySelector("video")
              .scrollIntoView({ behavior: "smooth", block: "center" });
            jump_video(event_data.seconds);
          },
          set_current_view: function (new_view) {
            this.current_view = new_view;
            router.push({ hash: "#" + new_view });
          },
          // Chat bot methods
          toggleChat: function() {
            // Toggle chat state
            this.chatOpen = !this.chatOpen;
            console.log("Chat open state: ", this.chatOpen);
            
            // If opening, scroll to bottom and focus on input
            if (this.chatOpen) {
              this.$nextTick(() => {
                this.scrollToBottom();
                // Focus the input field if chat is opened
                const inputField = this.$el.querySelector('#chat-input-field');
                if (inputField) {
                  inputField.focus();
                }
              });
            }
          },
          
          // Resize functionality
          startResize: function(e) {
            if (e.button !== 0) return; // Only respond to left mouse button
            
            this.isResizing = true;
            this.initialX = e.clientX;
            this.initialY = e.clientY;
            this.initialWidth = this.chatWidth;
            this.initialHeight = this.chatHeight;
            
            // Add resize visual indicator
            document.body.style.cursor = 'nwse-resize';
            document.documentElement.classList.add('select-none'); // Prevent text selection
            
            // Add event listeners for document to capture mouse movement
            document.addEventListener('mousemove', this.resize);
            document.addEventListener('mouseup', this.stopResize);
            
            // Create resize overlay for smoother experience
            const overlay = document.createElement('div');
            overlay.id = 'resize-overlay';
            overlay.style = 'position:fixed;top:0;left:0;width:100%;height:100%;z-index:9999;cursor:nwse-resize;';
            document.body.appendChild(overlay);
            
            // Prevent event bubbling
            e.stopPropagation();
            e.preventDefault();
          },
          
          resize: function(e) {
            if (this.isResizing) {
              // Calculate new width and height
              const newWidth = this.initialWidth + (e.clientX - this.initialX);
              const newHeight = this.initialHeight + (e.clientY - this.initialY);
              
              // Apply minimum dimensions
              this.chatWidth = Math.max(280, newWidth);
              this.chatHeight = Math.max(500, newHeight);
              
              // Apply maximum dimensions to prevent window from becoming too large
              const maxWidth = window.innerWidth * 0.8;
              const maxHeight = window.innerHeight * 0.8;
              this.chatWidth = Math.min(maxWidth, this.chatWidth);
              this.chatHeight = Math.min(maxHeight, this.chatHeight);
              
              // Scroll to bottom when resizing
              this.$nextTick(() => {
                this.scrollToBottom();
              });
            }
          },
          
          stopResize: function() {
            this.isResizing = false;
            document.removeEventListener('mousemove', this.resize);
            document.removeEventListener('mouseup', this.stopResize);
            
            // Remove resize visual indicator
            document.body.style.cursor = '';
            document.documentElement.classList.remove('select-none');
            
            // Remove resize overlay
            const overlay = document.getElementById('resize-overlay');
            if (overlay) overlay.parentNode.removeChild(overlay);
          },
          
          formatMessage: function(text) {
            // First, handle specific response patterns like the car detection example from the screenshot
            if (text.includes("appears in") && text.includes("Scene")) {
              // Split into intro and scenes
              const parts = text.split(': Scene');
              let formattedText = `<div class="mb-2 font-medium">${parts[0]}:</div>`;
              
              // Format each scene as a separate item with indentation and clear spacing
              const scenes = parts.slice(1);
              formattedText += '<div class="pl-3 space-y-2">';
              scenes.forEach(scene => {
                // Improve scene display with proper spacing and highlights
                let sceneText = scene.trim();
                
                // Format timestamps
                sceneText = sceneText.replace(/from (\d+):(\d+) to (\d+):(\d+)/g, 
                  'from <span class="text-blue-300 font-medium">$1:$2</span> to <span class="text-blue-300 font-medium">$3:$4</span>');
                
                // Format confidence
                sceneText = sceneText.replace(/\((\d+)% confidence\)/g, 
                  '(<span class="text-green-300 font-medium">$1%</span> confidence)');
                
                formattedText += `<div class="scene-item"><span class="font-bold text-blue-200">Scene${sceneText}</span></div>`;
              });
              formattedText += '</div>';
              
              return formattedText;
            }
            
            // Handle person/face count responses with better formatting
            if (text.includes("detected") && (text.includes("people") || text.includes("person") || text.includes("face"))) {
              return `<div class="font-medium">${text.replace(/(\d+)/g, '<span class="text-yellow-300 font-semibold">$1</span>')}</div>`;
            }
            
            // Standard formatting for other messages
            
            // Replace timestamps with formatted time
            text = text.replace(/(\d+):(\d+)(?::(\d+))?/g, (match, min, sec) => {
              return `<span class="text-blue-300 font-medium">${min}:${sec.padStart(2, '0')}</span>`;
            });
            
            // Highlight percentages
            text = text.replace(/(\d+)%/g, '<span class="text-green-300 font-medium">$1%</span>');
            
            // Format object names in quotes
            text = text.replace(/"([^"]+)"/g, '"<span class="text-yellow-300 font-medium">$1</span>"');
            
            // Format scene numbers
            text = text.replace(/(Scene \d+):/g, '<div class="font-bold text-blue-200 mt-2">$1:</div>');
            
            // Format list items
            text = text.replace(/\n-\s+(.+)$/gm, '<div class="mt-1 pl-2">â€¢ <span class="text-blue-100">$1</span></div>');
            
            // Add better paragraph breaks with spacing
            text = text.replace(/\. (?=[A-Z])/g, '.<div class="mt-1"></div>');
            
            return text;
          },
          
          sendMessage: function() {
            if (!this.userInput.trim()) return;
            
            // Add user message to chat
            this.chatMessages.push({
              sender: 'user',
              text: this.userInput
            });
            
            const query = this.userInput;
            this.userInput = '';
            
            // Show loading indicator
            this.isLoading = true;
            
            // Scroll to bottom
            this.$nextTick(() => {
              this.scrollToBottom();
            });
            
            // Call backend API
            this.askChatbot(query);
          },
          
          askChatbot: function(query) {
            // Show loading indicator
            this.isLoading = true;
            
            // Instead of making an API call, we'll simulate a response based on the loaded JSON data
            setTimeout(() => {
              try {
                // First try the direct approach
                let response = this.processQuery(query, this.json_data);
                
                // Check if the response is a generic "I don't have specific information" message
                if (response.startsWith("I don't have specific information")) {
                  console.log("Initial query didn't yield specific results, trying alternative approaches");
                  
                  // Try alternative query formulations
                  const queryVariations = [
                    // Extract just the key entities and try again
                    this.extractKeyEntities(query),
                    // Add specific search terms to help find relevant data
                    query + " object detection labels annotations",
                    // Try focusing on timeframes if the query might be about timing
                    query.includes("when") ? query + " timestamp time_offset seconds" : null
                  ].filter(q => q !== null); // Remove null variations
                  
                  // Try each variation until we get a specific answer
                  for (const variation of queryVariations) {
                    console.log("Trying variation:", variation);
                    const variationResponse = this.processQuery(variation, this.json_data);
                    
                    // If this variation gave a more specific response, use it
                    if (!variationResponse.startsWith("I don't have specific information")) {
                      response = "Based on my analysis: " + variationResponse;
                      break;
                    }
                  }
                }
                
                // Add bot response to chat
                this.chatMessages.push({
                  sender: 'bot',
                  text: response
                });
              } catch (error) {
                console.error("Error processing query:", error);
                
                // Add error message to chat
                this.chatMessages.push({
                  sender: 'bot',
                  text: "I'm sorry, I encountered an error processing your question. Please try asking something else."
                });
              } finally {
                this.isLoading = false;
                
                // Scroll to bottom
                this.$nextTick(() => {
                  this.scrollToBottom();
                });
              }
            }, 1000); // Simulate network delay
          },
          
          // Helper method to extract key entities from a query
          extractKeyEntities: function(query) {
            // Simple extraction of nouns and key terms
            const words = query.toLowerCase().split(/\s+/);
            const stopWords = ['a', 'an', 'the', 'is', 'are', 'was', 'were', 'in', 'on', 'at', 'by', 
                              'for', 'with', 'about', 'against', 'between', 'into', 'through', 
                              'during', 'before', 'after', 'above', 'below', 'from', 'up', 'down', 
                              'of', 'to', 'and', 'or', 'not', 'but', 'this', 'that', 'these', 'those',
                              'it', 'they', 'them', 'their', 'what', 'which', 'who', 'whom', 'whose',
                              'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few',
                              'more', 'most', 'some', 'such', 'no', 'nor', 'too', 'very', 'can', 
                              'will', 'just', 'should', 'now', 'do', 'does', 'did', 'have', 'has', 'had'];
            
            // Filter out stop words and short words
            const keyWords = words.filter(word => 
              word.length > 3 && !stopWords.includes(word)
            );
            
            return keyWords.join(' ');
          },
          
          // Add the processQuery function back
          processQuery: function(query, jsonData) {
            try {
              // Process the user query based on JSON data
              query = query.toLowerCase();
              
              // Check if annotation_results exists
              if (!jsonData || !jsonData.annotation_results || jsonData.annotation_results.length === 0) {
                return "I don't have any video analysis data to work with. Please upload a JSON file with video analysis results.";
              }

              // Add a function to deeply search through the JSON for relevant information
              function deepSearch(obj, searchTerms) {
                const results = [];
                
                function traverse(obj, path = '') {
                  if (!obj) return;
                  
                  // If object is an array, traverse each element
                  if (Array.isArray(obj)) {
                    obj.forEach((item, index) => {
                      traverse(item, `${path}[${index}]`);
                    });
                    return;
                  }
                  
                  // If object is an object, check each property
                  if (typeof obj === 'object') {
                    // Check if this object contains any of our search terms
                    let relevanceScore = 0;
                    const relevantProperties = {};
                    
                    for (const key in obj) {
                      if (typeof obj[key] === 'string') {
                        const lowerValue = obj[key].toLowerCase();
                        // Check if value contains any search term
                        searchTerms.forEach(term => {
                          if (lowerValue.includes(term)) {
                            relevanceScore += 2;
                            relevantProperties[key] = obj[key];
                          }
                        });
                      } else if (typeof obj[key] === 'number' && key.includes('confidence')) {
                        relevantProperties[key] = obj[key];
                      } else if (key.toLowerCase().includes('time') && typeof obj[key] === 'object' && obj[key] !== null) {
                        relevantProperties[key] = obj[key];
                      }
                      
                      // Check if key contains any search term
                      searchTerms.forEach(term => {
                        if (key.toLowerCase().includes(term)) {
                          relevanceScore += 1;
                          relevantProperties[key] = obj[key];
                        }
                      });
                    }
                    
                    // If this object is relevant, add it to results
                    if (relevanceScore > 0) {
                      results.push({
                        path,
                        relevanceScore,
                        properties: relevantProperties,
                        fullObject: obj
                      });
                    }
                    
                    // Continue traversing
                    for (const key in obj) {
                      traverse(obj[key], `${path}.${key}`);
                    }
                  }
                }
                
                traverse(obj);
                
                // Sort by relevance score
                results.sort((a, b) => b.relevanceScore - a.relevanceScore);
                return results;
              }
              
              // Get video duration
              let duration = "unknown";
              try {
                if (jsonData && jsonData.annotation_results && 
                    jsonData.annotation_results.length > 0 &&
                    jsonData.annotation_results[0].segment && 
                    jsonData.annotation_results[0].segment.end_time_offset && 
                    jsonData.annotation_results[0].segment.end_time_offset.seconds) {
                  const seconds = jsonData.annotation_results[0].segment.end_time_offset.seconds;
                  const minutes = Math.floor(seconds / 60);
                  const remainingSeconds = Math.round(seconds % 60);
                  duration = `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
                }
              } catch (error) {
                console.log("Error calculating duration:", error);
              }
              
              // Extract all annotations to analyze
              const segmentLabels = [];
              const shotLabels = {};
              const personDetections = [];
              const faceDetections = [];
              
              jsonData.annotation_results.forEach(result => {
                // Process segment labels (whole video level)
                if (result.segment_label_annotations) {
                  result.segment_label_annotations.forEach(annotation => {
                    if (annotation && annotation.entity && annotation.entity.description && 
                        annotation.segments && annotation.segments.length > 0 && 
                        annotation.segments[0].confidence !== undefined) {
                      const entity = annotation.entity.description;
                      const confidence = annotation.segments[0].confidence;
                      segmentLabels.push({
                        label: entity,
                        confidence: confidence
                      });
                    }
                  });
                }
                
                // Process shot labels (scene level)
                if (result.shot_label_annotations) {
                  result.shot_label_annotations.forEach(annotation => {
                    if (annotation && annotation.entity && annotation.entity.description) {
                      const entity = annotation.entity.description;
                      if (!shotLabels[entity]) {
                        shotLabels[entity] = [];
                      }
                      
                      if (annotation.segments) {
                        annotation.segments.forEach(segment => {
                          if (segment && segment.segment) {
                            const startTime = segment.segment.start_time_offset ? 
                              (segment.segment.start_time_offset.seconds || 0) : 0;
                            const endTime = segment.segment.end_time_offset ? 
                              (segment.segment.end_time_offset.seconds || 0) : 0;
                            
                            shotLabels[entity].push({
                              confidence: segment.confidence || 0,
                              startTime: startTime,
                              endTime: endTime
                            });
                          }
                        });
                      }
                    }
                  });
                }
                
                // Process person detections
                if (result.person_detection_annotations) {
                  result.person_detection_annotations.forEach(annotation => {
                    if (annotation && annotation.tracks) {
                      annotation.tracks.forEach(track => {
                        if (track && track.segments) {
                          track.segments.forEach(segment => {
                            if (segment && segment.segment) {
                              const startTime = segment.segment.start_time_offset ? 
                                (segment.segment.start_time_offset.seconds || 0) : 0;
                              const endTime = segment.segment.end_time_offset ? 
                                (segment.segment.end_time_offset.seconds || 0) : 0;
                              
                              personDetections.push({
                                startTime: startTime,
                                endTime: endTime,
                                confidence: segment.confidence || 0
                              });
                            }
                          });
                        }
                      });
                    }
                  });
                }
                
                // Process face detections
                if (result.face_detection_annotations) {
                  result.face_detection_annotations.forEach(annotation => {
                    if (annotation && annotation.tracks) {
                      annotation.tracks.forEach(track => {
                        if (track && track.segments) {
                          track.segments.forEach(segment => {
                            if (segment && segment.segment) {
                              const startTime = segment.segment.start_time_offset ? 
                                (segment.segment.start_time_offset.seconds || 0) : 0;
                              const endTime = segment.segment.end_time_offset ? 
                                (segment.segment.end_time_offset.seconds || 0) : 0;
                              
                              faceDetections.push({
                                startTime: startTime,
                                endTime: endTime,
                                confidence: segment.confidence || 0
                              });
                            }
                          });
                        }
                      });
                    }
                  });
                }
              });
              
              // Sort segment labels by confidence
              segmentLabels.sort((a, b) => b.confidence - a.confidence);
              
              // Handle person/face count queries
              if (query.includes("how many people") || query.includes("how many persons") || 
                  query.includes("number of people") || query.includes("count of people") ||
                  query.includes("people count") || query.includes("person count")) {
                  
                // First check if we have person detection data
                if (personDetections.length > 0) {
                  return `I detected ${personDetections.length} person instances in this video across different scenes.`;
                } 
                // If no person detection, check for person labels
                else if (shotLabels["person"] && shotLabels["person"].length > 0) {
                  return `I detected people in ${shotLabels["person"].length} different scenes of the video.`;
                }
                // If no person detection or labels, check for face detection
                else if (faceDetections.length > 0) {
                  return `I detected ${faceDetections.length} faces in this video across different scenes.`;
                }
                // If none of the above, try to find person-related labels
                else {
                  const personLabels = segmentLabels.filter(label => 
                    label.label.toLowerCase().includes("person") || 
                    label.label.toLowerCase().includes("people") ||
                    label.label.toLowerCase().includes("human")
                  );
                  
                  if (personLabels.length > 0) {
                    return `I detected people in the video with ${Math.round(personLabels[0].confidence * 100)}% confidence, but I don't have specific count information.`;
                  } else {
                    return "I don't have specific information about people in this video analysis.";
                  }
                }
              }
              
              // Handle face detection queries
              if (query.includes("how many face") || query.includes("face count") || 
                  query.includes("number of face") || query.includes("detect face")) {
                  
                if (faceDetections.length > 0) {
                  return `I detected ${faceDetections.length} faces in this video across different scenes.`;
                } else {
                  return "I don't have specific information about faces in this video analysis.";
                }
              }
              
              // Handle duration queries
              if (query.includes("duration") || query.includes("how long")) {
                const minutes = Math.floor(parseInt(duration.split(':')[0]));
                const seconds = parseInt(duration.split(':')[1]);
                return `The video duration is ${minutes} minute${minutes !== 1 ? 's' : ''} and ${seconds} second${seconds !== 1 ? 's' : ''}.`;
              }
              
              // Handle general content queries
              if (query.includes("what is in") || query.includes("what's in") || 
                  query.includes("what can you see") || query.includes("content") || 
                  query.includes("about")) {
                if (segmentLabels.length > 0) {
                  // Create a more structured response
                  let topLabels = segmentLabels.slice(0, 5);
                  let response = "Main elements detected in this video:";
                  
                  // Format each label on its own line with confidence
                  topLabels.forEach(label => {
                    const confidencePercent = Math.round(label.confidence * 100);
                    response += `\nScene contains "${label.label}" (${confidencePercent}% confidence)`;
                  });
                  
                  return response;
                } else {
                  return "No clear labels were detected in this video.";
                }
              }
              
              // Check for specific objects
              for (const label in shotLabels) {
                if (query.includes(label.toLowerCase())) {
                  const scenes = shotLabels[label];
                  if (scenes.length > 0) {
                    // Create a structured response with clear scene separation
                    let response = `Yes, "${label}" appears in ${scenes.length} scene${scenes.length > 1 ? 's' : ''}:`;
                    
                    // Format each scene as a separate item for better readability
                    scenes.forEach((scene, index) => {
                      const startMin = Math.floor(scene.startTime / 60);
                      const startSec = Math.round(scene.startTime % 60);
                      const endMin = Math.floor(scene.endTime / 60);
                      const endSec = Math.round(scene.endTime % 60);
                      const confidencePercent = Math.round(scene.confidence * 100);
                      
                      response += ` Scene ${index+1}: from ${startMin}:${startSec.toString().padStart(2, '0')} to ${endMin}:${endSec.toString().padStart(2, '0')} (${confidencePercent}% confidence)`;
                    });
                    
                    return response;
                  }
                }
              }
              
              // Try a deep search before giving up
              const searchTerms = query.split(/\s+/).filter(word => 
                word.length > 3 && 
                !['what', 'when', 'where', 'which', 'this', 'that', 'with', 'about', 'from', 'have', 'does'].includes(word)
              );
              
              if (searchTerms.length > 0) {
                console.log("Performing deep search for terms:", searchTerms);
                const deepSearchResults = deepSearch(jsonData, searchTerms);
                
                if (deepSearchResults.length > 0) {
                  // Found relevant information through deep search
                  const topResults = deepSearchResults.slice(0, 3); // Take top 3 most relevant results
                  
                  let response = "I found some information that might be relevant:";
                  
                  topResults.forEach(result => {
                    // Extract key information
                    const properties = result.properties;
                    
                    // Check for description/text content
                    let description = '';
                    for (const key in properties) {
                      if (key.includes('description') || key.includes('text') || key.includes('display_name')) {
                        description = properties[key];
                        break;
                      }
                    }
                    
                    // Check for confidence score
                    let confidence = null;
                    for (const key in properties) {
                      if (key.includes('confidence') && typeof properties[key] === 'number') {
                        confidence = Math.round(properties[key] * 100);
                        break;
                      }
                    }
                    
                    // Check for timestamps
                    let timeInfo = '';
                    for (const key in properties) {
                      if (key.includes('time') && properties[key].seconds) {
                        const seconds = properties[key].seconds;
                        const minutes = Math.floor(seconds / 60);
                        const remainingSeconds = Math.round(seconds % 60);
                        timeInfo += ` at ${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
                        break;
                      }
                    }
                    
                    // Add to response
                    if (description) {
                      response += `\n- Found "${description}"`;
                      if (confidence !== null) {
                        response += ` (${confidence}% confidence)`;
                      }
                      if (timeInfo) {
                        response += timeInfo;
                      }
                    }
                  });
                  
                  return response;
                }
              }
              
              // If we've exhausted all options, return the default response
              return "I don't have specific information about that in the video analysis. You can ask me about:\n- Video duration\n- How many people/faces are in the video\n- What objects are in the video\n- Specific objects like 'car', 'person', 'building', etc.";
            } catch (error) {
              console.error("Error processing query:", error);
              return "I'm sorry, I encountered an error processing your question. Please try asking something else.";
            }
          },
          
          scrollToBottom: function() {
            if (this.$refs.chatMessages) {
              this.$refs.chatMessages.scrollTop = this.$refs.chatMessages.scrollHeight;
            }
          }
        },
        computed: {
          data_misaligned: function () {
            console.log("delt");
            if (this.json_data)
              if (this.json_data.annotation_results) {
                const delta =
                  this.video_info.length -
                  this.json_data.annotation_results[0].segment.end_time_offset
                    .seconds;
                console.log("delt", delta);
                if (Math.abs(delta) > 2) {
                  return true;
                }
              }
            return false;
          },
          detected_features: function () {
            var features = [];

            if (!this.json_data.annotation_results) return features;

            this.json_data.annotation_results.forEach((annotations) => {
              console.log(Object.keys(annotations));
              features = features.concat(Object.keys(annotations));
            });

            return features;
          },
        },
      });

      const URL = window.URL || window.webkitURL;

      function fetch_json(url) {
        var json = null;
        $.ajax({
          async: false,
          url: url,
          dataType: "json",
          success: function (data) {
            json = data;
          },
        });
        return json;
      }

      function load_video_from_url(url) {
        video.src = url;
      }

      function load_video_dragged(event) {
        const file = this.files[0];
        const file_url = URL.createObjectURL(file);
        load_video_from_url(file_url);
      }

      function load_json_from_url(url) {
        var json = null;
        $.ajax({
          async: false,
          url: url,
          dataType: "json",
          success: function (data) {
            json = data;
          },
        });
        json_data = json;

        console.log(json_data);
        app.json_data = json_data;

        console.log("keys ->>", Object.keys(json_data));
        // check validity of json
        if (!("annotation_results" in json_data)) {
          alert(
            "âš ï¸ Sorry, json output from shell not supported âš ï¸ To fix set the 'output_uri' configuration when calling the Video Intelligence API so that it outputs a .json file to Google Cloud Storage, and then download that .json file. Find links to example script at the top right of the screen."
          );
          json_input.value = null;
        }
      }

      function load_json_dragged(event) {
        const file = this.files[0];
        const file_url = URL.createObjectURL(file);
        load_json_from_url(file_url);
      }

      var json_data = {};
      const video = document.getElementById("video");
      const video_input = document.getElementById("video_input");
      const json_input = document.getElementById("json_input");

      video.oncanplay = function () {
        console.log(
          "Can start playing video",
          video.duration,
          video.videoHeight,
          video.videoWidth
        );
        app.video_info.length = video.duration;
        app.video_length.duration;
        app.video_info.height = 500;
        app.video_info.width = 800;
      };

      function drag_enter(ev) {
        ev.preventDefault();
      }

      function drop_video(ev) {
        ev.preventDefault();
        video_input.files = ev.dataTransfer.files;
        video_input.dispatchEvent(new Event("change"));
      }

      function drop_json(ev) {
        ev.preventDefault();
        json_input.files = ev.dataTransfer.files;
        json_input.dispatchEvent(new Event("change"));
      }

      video_input.addEventListener("change", load_video_dragged, false);
      json_input.addEventListener("change", load_json_dragged, false);

      load_json_from_url("assets/test_json.json");
      load_video_from_url("assets/test_video.mp4");

      // check for hash code in url

      if (app.$route.hash) {
        const hash_value = decodeURI(app.$route.hash.substring(1));
        if (hash_value in app.title_ids_dict) {
          app.current_view = hash_value;
        }
      }
    </script>
    <script src="components/particles.js"></script>
  </body>
</html>
