<html>
  <head>
    <title>AIna</title>
    <link rel="icon" type="image/png" href="assets/Picture1.png" />

    <meta
      name="description"
      content="Interactive visualiser for the Google Cloud Video Intelligence API."
    />
    <meta
      name="keywords"
      content="google cloud, video, intelligence, api, video intelligence api, google cloud"
    />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/icon?family=Material+Icons"
    />
    <link
      rel="stylesheet"
      href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css"
    />
    <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>

    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
    <script src="https://unpkg.com/vue-router@2.0.0/dist/vue-router.js"></script>

    <!-- 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-N80GH8KX9W"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-N80GH8KX9W', { client_storage: 'none' });

    </script> -->

    <style>
      body {
          color:white;
          text-align: center;
          min-height: 1500px;
          min-width: 1130px;
          background-color:black;
          background-size:cover;

      }

      h1, h2, h3, h4, h5 {
        color: rgb(84, 47, 253);
      }

      #video-conatiner {
          position: relative;
          width: 800px;
          margin: 15px;
          display: inline-block;
          box-shadow: 0 4px 20px rgb(84, 47, 253);
          border-radius: 8px;
      }

      #video-conatiner>canvas {
          width: 100%;
          position: absolute;
          opacity: 0.8;
          left: 0;
          height: 100%;
          pointer-events: none;
          box-shadow: 0 4px 20px rgb(84, 47, 253);
          border-radius: 8px;
      }

      video {
          width: 100%;
          margin: auto;
          display: block;
      }

      video::-webkit-media-controls-fullscreen-button {
          display: none !important;
      }

      .upload-area {
        color:aliceblue;
        /* display: inline-block; */
        width: 200px;
        /* height: 62px; */
        border: dashed #ededed 3px;
        border-radius: 5px;
        padding: 15px;
        margin: 15px;
        overflow: hidden;
    }

      .mdl-layout__header {
          background-color: transparent;
          color: #e0e0e0;
          font-weight: 900;
          text-shadow: 1px 1px 2px rgba(0,0,0,0.5);
          padding-left: 40%;
      }

      #upload-data {
          display: inline-block;
          text-align: center;
          vertical-align: top;
          width: 250px;
      }

      #upload-data>p {
          text-align: justify;
      }

      .feature-tabs {
          margin: 30px;
          text-align: center;
      }

      .feature-tabs>div {
          display: inline-block;
          font-size: 1.2em;
          padding: 12px;
          cursor: pointer;
          color: #777777;
          font-weight: 300;

          border: solid #4285f4 1px;
          border-radius: 5px;
          margin: 5px;
      }

      .feature-tabs>div:hover {
          background-color: #4285f41a;
      }


      .feature-tabs>.selected {
          border-bottom: 2px solid #4285F4;
      }

      .feature-tabs>.disabled {
          color: #cdcdcd;
      }

      .logo {
          width: inherit;
      }


      .data-warning {
          background-color: #ffffc3;
          /* display: inline-block; */
          margin: auto;
          position: relative;
          padding: 15px;
          text-align: center;
      }

      .material-icons {
          vertical-align: middle;
          font-size: 19px;
      }

      .nav-tab>.material-icons {
          color: #0F9D58;
      }

      .search-container {
          margin: 20px;
          text-align: center;
      }

      .search-input-container {
          display: flex;
          justify-content: center;
          align-items: center;
      }

      .search-container input {
          width: 300px;
          padding: 5px;
          font-size: 16px;
          margin-right: 10px;
      }

      .search-button {
          padding: 5px 10px;
          font-size: 16px;
          background-color: #4285F4;
          color: white;
          border: none;
          cursor: pointer;
      }

      .search-button:hover {
          background-color: #3367D6;
      }

      .search-results {
          margin-top: 10px;
          max-height: 200px;
          overflow-y: auto;
          border: 1px solid #ccc;
          border-radius: 5px;
      }

      .search-result {
          padding: 5px;
          cursor: pointer;
          display: flex;
          justify-content: space-between;
      }

      .search-result:hover {
          background-color: #f0f0f0;
      }
      canvas {
          position: fixed;
          inset: 0;
          pointer-events: none;
          z-index: 0;
        }
    </style>
  </head>

  <body>
    <div id="app" class="mdl-layout--fixed-header">
      <canvas id="particleCanvas"></canvas>
      <header class="relative mb-14">
        <!-- Background Image Layer with Blur -->
        <div
          class="absolute inset-0 bg-[url('assets/header-bg.jpg')] bg-cover bg-center backdrop-blur-md opacity-60 z-0"
        ></div>
      
        <!-- Header Content -->
        <div class="relative z-10 bg-gray-900/70 px-6 py-4 shadow-xl border-b border-blue-900">
          <div class="container mx-auto flex items-center justify-between">
            <!-- Logo and Brand Name -->
            <div class="flex items-center space-x-3">
              <img src="assets/Picture1.png" alt="Logo" class="h-12 w-auto" />
            </div>
            <span class="text-3xl font-bold text-blue-400">AIna</span>
          </div>
        </div>
      </header>
      <div class="text-center mx-auto mb-4 px-4 font-extrabold">
        <h5 class="text-3xl md:text-4xl font-extrabold mb-4 text-blue-300 leading-snug">
          Unlock the Power of Video with AI
        </h5>
        
        <p class="text-lg md:text-xl text-blue-200 leading-relaxed">
          Annotate Video using this script right
          <a
            target="_blank"
            href="https://colab.research.google.com/drive/18atVgKfkiGSTuZgTS2G27GMqmkwNmsRr?usp=sharing"
            class="text-blue-400 underline hover:text-blue-300 transition font-semibold"
          >
            here
          </a>
          if you want to run all features at once.
        </p>
      </div>
      <div id="video-conatiner">
        <canvas id="my_canvas" width="800" height="500"></canvas>
        <video id="video" controls autoplay></video>
      </div>

      <div 
  id="upload-data" 
  class="flex flex-col md:flex-row gap-8 justify-center items-center mt-16 w-full max-w-4xl mx-auto px-4"
>
  <!-- Video Upload -->
  <label
    for="video_input"
    class="upload-area w-full md:w-80 h-48 flex flex-col justify-center items-center border-2 border-dashed border-gray-400 rounded-lg p-6 text-white bg-black/30 hover:bg-black/40 hover:border-blue-500 transition-all cursor-pointer relative overflow-hidden group"
    ondrop="drop_video(event)"
    ondragover="dragOver(event)"
    ondragleave="dragLeave(event)"
  >
    <div class="absolute inset-0 bg-blue-500/10 scale-y-0 group-hover:scale-y-100 transition-transform origin-bottom"></div>
    <svg class="w-12 h-12 text-gray-300 mb-3" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 4v16M17 4v16M3 8h18M3 16h18"></path>
    </svg>
    <p class="text-base font-medium mb-2 relative z-10">Upload Your Video</p>
    <input id="video_input" type="file" accept="video/*" class="hidden" />
    <span class="text-sm text-gray-300 relative z-10">Drop file here or click to browse</span>
    <span class="text-xs text-gray-400 mt-2 relative z-10">MP4, WebM, AVI, MOV, etc.</span>
    <div id="video_preview" class="mt-2 hidden"></div>
  </label>
  
  <!-- JSON Upload -->
  <label
    for="json_input"
    class="upload-area w-full md:w-80 h-48 flex flex-col justify-center items-center border-2 mt-4 border-dashed border-gray-400 rounded-lg p-6 text-white bg-black/30 hover:bg-black/40 hover:border-blue-500 transition-all cursor-pointer relative overflow-hidden group"
    ondrop="drop_json(event)"
    ondragover="dragOver(event)"
    ondragleave="dragLeave(event)"
  >
    <div class="absolute inset-0 bg-blue-500/10 scale-y-0 group-hover:scale-y-100 transition-transform origin-bottom"></div>
    <svg class="w-12 h-12 text-gray-300 mb-3" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
    </svg>
    <p class="text-base font-medium mb-2 relative z-10">Upload Your .JSON</p>
    <input id="json_input" type="file" accept="application/JSON" class="hidden" />
    <span class="text-sm text-gray-300 relative z-10">Drop file here or click to browse</span>
    <span class="text-xs text-gray-400 mt-2 relative z-10">Metadata or Config Files</span>
    <div id="json_preview" class="mt-2 hidden"></div>
  </label>
</div>


    <div
    v-if="data_misaligned"
    class="data-warning bg-blue-100 border-l-4 border-blue-500 text-blue-700 p-4 rounded-md shadow-sm max-w-xl mx-auto mt-4"
    >
    <p class="font-semibold">Data Misalignment Detected</p>
    <p class="text-sm">
    It looks like the JSON data doesn't align with the video file. Are you sure
    you've uploaded the correct files?
    </p>
    </div>

      <annotations-nav
        v-bind:title_ids_dict="title_ids_dict"
        v-bind:detected_features="detected_features"
        v-bind:current_view="current_view"
        v-on:nav-clicked="set_current_view"
      >
      </annotations-nav>

      <object-tracking-viz
        v-if="current_view == 'Object Tracking'"
        id="object_tracks"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      ></object-tracking-viz>

      <label-detection-viz
        v-if="current_view == 'Label Detection'"
        id="label_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      ></label-detection-viz>

      <shot-detection-viz
        v-if="current_view == 'Shot Detection'"
        id="shot_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:shot-clicked="jump_video"
      ></shot-detection-viz>

      <speech-transcription-viz
        v-if="current_view == 'Speech Transcription'"
        id="speech_transcription"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:word-clicked="jump_video"
      >
      </speech-transcription-viz>

      <person-detection-viz
        v-if="current_view == 'Person Detection'"
        id="person_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </person-detection-viz>

      <face-detection-viz
        v-if="current_view == 'Face Detection'"
        id="face_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </face-detection-viz>

      <logo-recognition-viz
        v-if="current_view == 'Logo Recognition'"
        id="logo_recognition"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </logo-recognition-viz>

      <text-detection-viz
        v-if="current_view == 'Text Detection'"
        id="text_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:segment-clicked="jump_video"
      >
      </text-detection-viz>

      <explicit-content-detection-viz
        v-if="current_view == 'Explicit Content Detection'"
        id="explicit_content_detection"
        v-bind:json_data="json_data"
        v-bind:video_info="video_info"
        v-on:shot-clicked="jump_video"
      >
      </explicit-content-detection-viz>

      <search-component
        v-bind:json_data="json_data"
        v-on:jump-to-time="jump_video"
      ></search-component>
      
      <!-- Chat Bot Window -->
      <div id="chat-bot-container" class="fixed bottom-4 right-4 w-80 bg-gray-900 rounded-lg shadow-xl border border-blue-500 overflow-hidden transition-all duration-300 z-50" :class="{'h-96': chatOpen, 'h-12': !chatOpen}" :style="chatOpen ? { width: chatWidth + 'px', height: chatHeight + 'px' } : {}">
        <!-- Chat Header -->
        <div class="bg-blue-600 px-4 py-2 flex justify-between items-center cursor-pointer">
          <div class="flex items-center" @click="toggleChat">
            <img src="assets/Picture1.png" alt="AIna Bot" class="h-6 w-6 mr-2">
            <h3 class="text-white font-medium font-sans">AIna Assistant</h3>
          </div>
          <div class="flex items-center">
            <!-- Resize handle -->
            <button v-if="chatOpen" @mousedown="startResize" class="text-white focus:outline-none mr-2 hover:text-blue-200">
              <span class="material-icons text-sm">open_with</span>
            </button>
            <!-- Minimize/Maximize button -->
            <button class="text-white focus:outline-none" @click="toggleChat">
              <span v-if="chatOpen" class="material-icons">expand_more</span>
              <span v-else class="material-icons">expand_less</span>
            </button>
          </div>
        </div>
        
        <!-- Chat Messages with improved display and better fonts -->
        <div v-if="chatOpen" class="overflow-y-auto bg-gray-800 font-sans" ref="chatMessages" :style="{ height: (chatHeight - 96) + 'px' }">
          <div v-for="(message, index) in chatMessages" :key="index" 
               :class="{'flex justify-end': message.sender === 'user', 'flex justify-start': message.sender === 'bot'}"
               class="p-3">
            <div :class="{
                  'bg-blue-600 text-white max-w-xs': message.sender === 'user', 
                  'bg-gray-700 text-gray-200': message.sender === 'bot',
                  'max-w-xs': !message.text.includes('Scene') && !message.text.includes('detect'),
                  'max-w-md': message.text.includes('Scene') || message.text.includes('detect')
                }" 
                class="rounded-lg px-4 py-3 shadow-md">
              <p v-if="message.sender === 'bot'" class="text-xs text-blue-300 mb-1 font-semibold">AIna</p>
              <p v-else class="text-xs text-blue-200 mb-1 font-semibold">You</p>
              <div class="text-sm leading-relaxed font-sans whitespace-pre-line" v-html="formatMessage(message.text)"></div>
            </div>
          </div>
          <div v-if="isLoading" class="flex justify-start p-3">
            <div class="bg-gray-700 text-gray-200 rounded-lg px-4 py-2 shadow-md">
              <p class="text-xs text-blue-300 mb-1 font-semibold">AIna</p>
              <div class="flex space-x-1">
                <div class="w-2 h-2 bg-blue-400 rounded-full animate-bounce"></div>
                <div class="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style="animation-delay: 0.2s"></div>
                <div class="w-2 h-2 bg-blue-400 rounded-full animate-bounce" style="animation-delay: 0.4s"></div>
              </div>
            </div>
          </div>
        </div>
        
        <!-- Chat Input -->
        <div v-if="chatOpen" class="bg-gray-700 p-3 border-t border-gray-600">
          <div class="flex">
            <input 
              type="text" 
              v-model="userInput" 
              @keyup.enter="sendMessage"
              placeholder="Ask about the video..." 
              class="flex-1 bg-gray-800 text-white rounded-l-lg px-3 py-2 focus:outline-none border border-gray-600 font-sans"
            >
            <button 
              @click="sendMessage" 
              class="bg-blue-600 text-white px-4 py-2 rounded-r-lg hover:bg-blue-700 focus:outline-none"
            >
              <span class="material-icons text-sm">send</span>
            </button>
          </div>
        </div>
      </div>
    </div>

    <script src="utils/utils.js"></script>

    <script src="components/object_tracking.js"></script>
    <script src="components/label_detection.js"></script>
    <script src="components/shot_detection.js"></script>
    <script src="components/speech_transcription.js"></script>
    <script src="components/person_detection.js"></script>
    <script src="components/face_detection.js"></script>
    <script src="components/logo_recognition.js"></script>
    <script src="components/text_detection.js"></script>
    <script src="components/explicit_content_detection.js"></script>
    <script src="components/search.js"></script>

    <script>
      function jump_video(time) {
        const video = document.querySelector("video");
        video.currentTime = time;
        video.play();
      }

      // define component
      Vue.component("annotations-nav-tab", {
        props: ["title", "current_view", "data_id", "detected_features"],
        computed: {
          has_data: function () {
            return this.detected_features.includes(this.data_id);
          },
        },
        template: `
            <div class="nav-tab" v-bind:class="{selected:current_view == title, disabled:(!has_data)}">{{title}}
                <span v-if="has_data" class="material-icons">
                    check_circle
                </span>
            </div>
            `,
      });

      Vue.component("annotations-nav", {
        props: ["title_ids_dict", "current_view", "detected_features"],
        methods: {
          nav_clicked: function (title) {
            this.$emit("nav-clicked", title);
          },
        },
        template: `
            <div class="feature-tabs">
                <annotations-nav-tab v-for="id, title in title_ids_dict"
                    v-bind:title="title" v-bind:data_id="id"
                    v-bind:detected_features="detected_features" v-bind:current_view="current_view"
                    v-on:click.native="nav_clicked(title)">
                </annotations-nav-tab>
            </div>
            `,
      });

      var router = new VueRouter({
        mode: "history",
        // routes: { path: '/match/:id', component: test_com}
      });

      var app = new Vue({
        router,
        el: "#app",
        data: {
          json_data: {},
          video_info: { width: 800, height: 500, length: 252 },
          video_length: 252,
          current_view: "Label Detection",
          title_ids_dict: {
            "Label Detection": "shot_label_annotations",
            "Shot Detection": "shot_annotations",
            "Object Tracking": "object_annotations",
            "Person Detection": "person_detection_annotations",
            "Face Detection": "face_detection_annotations",
            "Logo Recognition": "logo_recognition_annotations",
            "Speech Transcription": "speech_transcriptions",
            "Text Detection": "text_annotations",
            "Explicit Content Detection": "explicit_annotation",
          },
          // Chat bot related data
          chatOpen: false,
          chatMessages: [
            {
              sender: 'bot',
              text: 'Hello! I can help answer questions about this video. What would you like to know?'
            }
          ],
          userInput: '',
          isLoading: false,
          // Chat window size
          chatWidth: 320,
          chatHeight: 384,
          isResizing: false,
          initialX: 0,
          initialY: 0,
          initialWidth: 320,
          initialHeight: 384
        },
        methods: {
          jump_video: function (event_data) {
            document
              .querySelector("video")
              .scrollIntoView({ behavior: "smooth", block: "center" });
            jump_video(event_data.seconds);
          },
          set_current_view: function (new_view) {
            this.current_view = new_view;
            router.push({ hash: "#" + new_view });
          },
          // Chat bot methods
          toggleChat: function() {
            this.chatOpen = !this.chatOpen;
            if (this.chatOpen) {
              this.$nextTick(() => {
                this.scrollToBottom();
              });
            }
          },
          
          // Resize functionality
          startResize: function(e) {
            this.isResizing = true;
            this.initialX = e.clientX;
            this.initialY = e.clientY;
            this.initialWidth = this.chatWidth;
            this.initialHeight = this.chatHeight;
            
            // Add resize visual indicator
            document.body.style.cursor = 'nwse-resize';
            
            // Add event listeners
            document.addEventListener('mousemove', this.resize);
            document.addEventListener('mouseup', this.stopResize);
            
            // Create resize overlay for smoother experience
            const overlay = document.createElement('div');
            overlay.id = 'resize-overlay';
            overlay.style = 'position:fixed;top:0;left:0;width:100%;height:100%;z-index:9999;cursor:nwse-resize;';
            document.body.appendChild(overlay);
            
            // Prevent text selection during resize
            e.preventDefault();
          },
          
          resize: function(e) {
            if (this.isResizing) {
              // Calculate new width and height
              const newWidth = this.initialWidth + (e.clientX - this.initialX);
              const newHeight = this.initialHeight + (e.clientY - this.initialY);
              
              // Apply minimum dimensions
              this.chatWidth = Math.max(280, newWidth);
              this.chatHeight = Math.max(300, newHeight);
              
              // Scroll to bottom when resizing
              this.$nextTick(() => {
                this.scrollToBottom();
              });
            }
          },
          
          stopResize: function() {
            this.isResizing = false;
            document.removeEventListener('mousemove', this.resize);
            document.removeEventListener('mouseup', this.stopResize);
            
            // Remove resize visual indicator
            document.body.style.cursor = '';
            
            // Remove resize overlay
            const overlay = document.getElementById('resize-overlay');
            if (overlay) {
              overlay.parentNode.removeChild(overlay);
            }
          },
          
          formatMessage: function(text) {
            // First, handle specific response patterns like the car detection example from the screenshot
            if (text.includes("appears in") && text.includes("Scene")) {
              // Split into intro and scenes
              const parts = text.split(': Scene');
              let formattedText = `<div class="mb-2 font-medium">${parts[0]}:</div>`;
              
              // Format each scene as a separate item with indentation and clear spacing
              const scenes = parts.slice(1);
              formattedText += '<div class="pl-3 space-y-2">';
              scenes.forEach(scene => {
                // Improve scene display with proper spacing and highlights
                let sceneText = scene.trim();
                
                // Format timestamps
                sceneText = sceneText.replace(/from (\d+):(\d+) to (\d+):(\d+)/g, 
                  'from <span class="text-blue-300 font-medium">$1:$2</span> to <span class="text-blue-300 font-medium">$3:$4</span>');
                
                // Format confidence
                sceneText = sceneText.replace(/\((\d+)% confidence\)/g, 
                  '(<span class="text-green-300 font-medium">$1%</span> confidence)');
                
                formattedText += `<div class="scene-item"><span class="font-bold text-blue-200">Scene${sceneText}</span></div>`;
              });
              formattedText += '</div>';
              
              return formattedText;
            }
            
            // Handle person/face count responses with better formatting
            if (text.includes("detected") && (text.includes("people") || text.includes("person") || text.includes("face"))) {
              return `<div class="font-medium">${text.replace(/(\d+)/g, '<span class="text-yellow-300 font-semibold">$1</span>')}</div>`;
            }
            
            // Standard formatting for other messages
            
            // Replace timestamps with formatted time
            text = text.replace(/(\d+):(\d+)(?::(\d+))?/g, (match, min, sec) => {
              return `<span class="text-blue-300 font-medium">${min}:${sec.padStart(2, '0')}</span>`;
            });
            
            // Highlight percentages
            text = text.replace(/(\d+)%/g, '<span class="text-green-300 font-medium">$1%</span>');
            
            // Format object names in quotes
            text = text.replace(/"([^"]+)"/g, '"<span class="text-yellow-300 font-medium">$1</span>"');
            
            // Format scene numbers
            text = text.replace(/(Scene \d+):/g, '<div class="font-bold text-blue-200 mt-2">$1:</div>');
            
            // Format list items
            text = text.replace(/\n-\s+(.+)$/gm, '<div class="mt-1 pl-2">• <span class="text-blue-100">$1</span></div>');
            
            // Add better paragraph breaks with spacing
            text = text.replace(/\. (?=[A-Z])/g, '.<div class="mt-1"></div>');
            
            return text;
          },
          
          sendMessage: function() {
            if (!this.userInput.trim()) return;
            
            // Add user message to chat
            this.chatMessages.push({
              sender: 'user',
              text: this.userInput
            });
            
            const query = this.userInput;
            this.userInput = '';
            
            // Show loading indicator
            this.isLoading = true;
            
            // Scroll to bottom
            this.$nextTick(() => {
              this.scrollToBottom();
            });
            
            // Call backend API
            this.askChatbot(query);
          },
          
          askChatbot: function(query) {
            // Show loading indicator
            this.isLoading = true;
            
            // Instead of making an API call, we'll simulate a response based on the loaded JSON data
            setTimeout(() => {
              try {
                // Process the query using the already loaded JSON data
                const response = this.processQuery(query, this.json_data);
                
                // Add bot response to chat
                this.chatMessages.push({
                  sender: 'bot',
                  text: response
                });
              } catch (error) {
                console.error("Error processing query:", error);
                
                // Add error message to chat
                this.chatMessages.push({
                  sender: 'bot',
                  text: "I'm sorry, I encountered an error processing your question. Please try asking something else."
                });
              } finally {
                this.isLoading = false;
                
                // Scroll to bottom
                this.$nextTick(() => {
                  this.scrollToBottom();
                });
              }
            }, 1000); // Simulate network delay
          },
          
          processQuery: function(query, jsonData) {
            try {
              // Process the user query based on JSON data
              query = query.toLowerCase();
              
              // Check if annotation_results exists
              if (!jsonData || !jsonData.annotation_results || jsonData.annotation_results.length === 0) {
                return "I don't have any video analysis data to work with. Please upload a JSON file with video analysis results.";
              }
              
              // Get video duration
              let duration = "unknown";
              try {
                if (jsonData && jsonData.annotation_results && 
                    jsonData.annotation_results.length > 0 &&
                    jsonData.annotation_results[0].segment && 
                    jsonData.annotation_results[0].segment.end_time_offset && 
                    jsonData.annotation_results[0].segment.end_time_offset.seconds) {
                  const seconds = jsonData.annotation_results[0].segment.end_time_offset.seconds;
                  const minutes = Math.floor(seconds / 60);
                  const remainingSeconds = Math.round(seconds % 60);
                  duration = `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
                }
              } catch (error) {
                console.log("Error calculating duration:", error);
              }
              
              // Extract all annotations to analyze
              const segmentLabels = [];
              const shotLabels = {};
              const personDetections = [];
              const faceDetections = [];
              
              jsonData.annotation_results.forEach(result => {
                // Process segment labels (whole video level)
                if (result.segment_label_annotations) {
                  result.segment_label_annotations.forEach(annotation => {
                    if (annotation && annotation.entity && annotation.entity.description && 
                        annotation.segments && annotation.segments.length > 0 && 
                        annotation.segments[0].confidence !== undefined) {
                      const entity = annotation.entity.description;
                      const confidence = annotation.segments[0].confidence;
                      segmentLabels.push({
                        label: entity,
                        confidence: confidence
                      });
                    }
                  });
                }
                
                // Process shot labels (scene level)
                if (result.shot_label_annotations) {
                  result.shot_label_annotations.forEach(annotation => {
                    if (annotation && annotation.entity && annotation.entity.description) {
                      const entity = annotation.entity.description;
                      if (!shotLabels[entity]) {
                        shotLabels[entity] = [];
                      }
                      
                      if (annotation.segments) {
                        annotation.segments.forEach(segment => {
                          if (segment && segment.segment) {
                            const startTime = segment.segment.start_time_offset ? 
                              (segment.segment.start_time_offset.seconds || 0) : 0;
                            const endTime = segment.segment.end_time_offset ? 
                              (segment.segment.end_time_offset.seconds || 0) : 0;
                            
                            shotLabels[entity].push({
                              confidence: segment.confidence || 0,
                              startTime: startTime,
                              endTime: endTime
                            });
                          }
                        });
                      }
                    }
                  });
                }
                
                // Process person detections
                if (result.person_detection_annotations) {
                  result.person_detection_annotations.forEach(annotation => {
                    if (annotation && annotation.tracks) {
                      annotation.tracks.forEach(track => {
                        if (track && track.segments) {
                          track.segments.forEach(segment => {
                            if (segment && segment.segment) {
                              const startTime = segment.segment.start_time_offset ? 
                                (segment.segment.start_time_offset.seconds || 0) : 0;
                              const endTime = segment.segment.end_time_offset ? 
                                (segment.segment.end_time_offset.seconds || 0) : 0;
                              
                              personDetections.push({
                                startTime: startTime,
                                endTime: endTime,
                                confidence: segment.confidence || 0
                              });
                            }
                          });
                        }
                      });
                    }
                  });
                }
                
                // Process face detections
                if (result.face_detection_annotations) {
                  result.face_detection_annotations.forEach(annotation => {
                    if (annotation && annotation.tracks) {
                      annotation.tracks.forEach(track => {
                        if (track && track.segments) {
                          track.segments.forEach(segment => {
                            if (segment && segment.segment) {
                              const startTime = segment.segment.start_time_offset ? 
                                (segment.segment.start_time_offset.seconds || 0) : 0;
                              const endTime = segment.segment.end_time_offset ? 
                                (segment.segment.end_time_offset.seconds || 0) : 0;
                              
                              faceDetections.push({
                                startTime: startTime,
                                endTime: endTime,
                                confidence: segment.confidence || 0
                              });
                            }
                          });
                        }
                      });
                    }
                  });
                }
              });
              
              // Sort segment labels by confidence
              segmentLabels.sort((a, b) => b.confidence - a.confidence);
              
              // Handle person/face count queries
              if (query.includes("how many people") || query.includes("how many persons") || 
                  query.includes("number of people") || query.includes("count of people") ||
                  query.includes("people count") || query.includes("person count")) {
                  
                // First check if we have person detection data
                if (personDetections.length > 0) {
                  return `I detected ${personDetections.length} person instances in this video across different scenes.`;
                } 
                // If no person detection, check for person labels
                else if (shotLabels["person"] && shotLabels["person"].length > 0) {
                  return `I detected people in ${shotLabels["person"].length} different scenes of the video.`;
                }
                // If no person detection or labels, check for face detection
                else if (faceDetections.length > 0) {
                  return `I detected ${faceDetections.length} faces in this video across different scenes.`;
                }
                // If none of the above, try to find person-related labels
                else {
                  const personLabels = segmentLabels.filter(label => 
                    label.label.toLowerCase().includes("person") || 
                    label.label.toLowerCase().includes("people") ||
                    label.label.toLowerCase().includes("human")
                  );
                  
                  if (personLabels.length > 0) {
                    return `I detected people in the video with ${Math.round(personLabels[0].confidence * 100)}% confidence, but I don't have specific count information.`;
                  } else {
                    return "I don't have specific information about people in this video analysis.";
                  }
                }
              }
              
              // Handle face detection queries
              if (query.includes("how many face") || query.includes("face count") || 
                  query.includes("number of face") || query.includes("detect face")) {
                  
                if (faceDetections.length > 0) {
                  return `I detected ${faceDetections.length} faces in this video across different scenes.`;
                } else {
                  return "I don't have specific information about faces in this video analysis.";
                }
              }
              
              // Handle duration queries
              if (query.includes("duration") || query.includes("how long")) {
                const minutes = Math.floor(parseInt(duration.split(':')[0]));
                const seconds = parseInt(duration.split(':')[1]);
                return `The video duration is ${minutes} minute${minutes !== 1 ? 's' : ''} and ${seconds} second${seconds !== 1 ? 's' : ''}.`;
              }
              
              // Handle general content queries
              if (query.includes("what is in") || query.includes("what's in") || 
                  query.includes("what can you see") || query.includes("content") || 
                  query.includes("about")) {
                if (segmentLabels.length > 0) {
                  // Create a more structured response
                  let topLabels = segmentLabels.slice(0, 5);
                  let response = "Main elements detected in this video:";
                  
                  // Format each label on its own line with confidence
                  topLabels.forEach(label => {
                    const confidencePercent = Math.round(label.confidence * 100);
                    response += `\nScene contains "${label.label}" (${confidencePercent}% confidence)`;
                  });
                  
                  return response;
                } else {
                  return "No clear labels were detected in this video.";
                }
              }
              
              // Check for specific objects
              for (const label in shotLabels) {
                if (query.includes(label.toLowerCase())) {
                  const scenes = shotLabels[label];
                  if (scenes.length > 0) {
                    // Create a structured response with clear scene separation
                    let response = `Yes, "${label}" appears in ${scenes.length} scene${scenes.length > 1 ? 's' : ''}:`;
                    
                    // Format each scene as a separate item for better readability
                    scenes.forEach((scene, index) => {
                      const startMin = Math.floor(scene.startTime / 60);
                      const startSec = Math.round(scene.startTime % 60);
                      const endMin = Math.floor(scene.endTime / 60);
                      const endSec = Math.round(scene.endTime % 60);
                      const confidencePercent = Math.round(scene.confidence * 100);
                      
                      response += ` Scene ${index+1}: from ${startMin}:${startSec.toString().padStart(2, '0')} to ${endMin}:${endSec.toString().padStart(2, '0')} (${confidencePercent}% confidence)`;
                    });
                    
                    return response;
                  }
                }
              }
              
              // Default response with suggested queries
              return "I don't have specific information about that in the video analysis. You can ask me about:\n- Video duration\n- How many people/faces are in the video\n- What objects are in the video\n- Specific objects like 'car', 'person', 'building', etc.";
            } catch (error) {
              console.error("Error processing query:", error);
              return "I'm sorry, I encountered an error processing your question. Please try asking something else.";
            }
          },
          scrollToBottom: function() {
            if (this.$refs.chatMessages) {
              this.$refs.chatMessages.scrollTop = this.$refs.chatMessages.scrollHeight;
            }
          }
        },
        computed: {
          data_misaligned: function () {
            console.log("delt");
            if (this.json_data)
              if (this.json_data.annotation_results) {
                const delta =
                  this.video_info.length -
                  this.json_data.annotation_results[0].segment.end_time_offset
                    .seconds;
                console.log("delt", delta);
                if (Math.abs(delta) > 2) {
                  return true;
                }
              }
            return false;
          },
          detected_features: function () {
            var features = [];

            if (!this.json_data.annotation_results) return features;

            this.json_data.annotation_results.forEach((annotations) => {
              console.log(Object.keys(annotations));
              features = features.concat(Object.keys(annotations));
            });

            return features;
          },
        },
      });

      const URL = window.URL || window.webkitURL;

      function fetch_json(url) {
        var json = null;
        $.ajax({
          async: false,
          url: url,
          dataType: "json",
          success: function (data) {
            json = data;
          },
        });
        return json;
      }

      function load_video_from_url(url) {
        video.src = url;
      }

      function load_video_dragged(event) {
        const file = this.files[0];
        const file_url = URL.createObjectURL(file);
        load_video_from_url(file_url);
      }

      function load_json_from_url(url) {
        var json = null;
        $.ajax({
          async: false,
          url: url,
          dataType: "json",
          success: function (data) {
            json = data;
          },
        });
        json_data = json;

        console.log(json_data);
        app.json_data = json_data;

        console.log("keys ->>", Object.keys(json_data));
        // check validity of json
        if (!("annotation_results" in json_data)) {
          alert(
            "⚠️ Sorry, json output from shell not supported ⚠️ To fix set the 'output_uri' configuration when calling the Video Intelligence API so that it outputs a .json file to Google Cloud Storage, and then download that .json file. Find links to example script at the top right of the screen."
          );
          json_input.value = null;
        }
      }

      function load_json_dragged(event) {
        const file = this.files[0];
        const file_url = URL.createObjectURL(file);
        load_json_from_url(file_url);
      }

      var json_data = {};
      const video = document.getElementById("video");
      const video_input = document.getElementById("video_input");
      const json_input = document.getElementById("json_input");

      video.oncanplay = function () {
        console.log(
          "Can start playing video",
          video.duration,
          video.videoHeight,
          video.videoWidth
        );
        app.video_info.length = video.duration;
        app.video_length.duration;
        app.video_info.height = 500;
        app.video_info.width = 800;
      };

      function drag_enter(ev) {
        ev.preventDefault();
      }

      function drop_video(ev) {
        ev.preventDefault();
        video_input.files = ev.dataTransfer.files;
        video_input.dispatchEvent(new Event("change"));
      }

      function drop_json(ev) {
        ev.preventDefault();
        json_input.files = ev.dataTransfer.files;
        json_input.dispatchEvent(new Event("change"));
      }

      video_input.addEventListener("change", load_video_dragged, false);
      json_input.addEventListener("change", load_json_dragged, false);

      load_json_from_url("assets/test_json.json");
      load_video_from_url("assets/test_video.mp4");

      // check for hash code in url

      if (app.$route.hash) {
        const hash_value = decodeURI(app.$route.hash.substring(1));
        if (hash_value in app.title_ids_dict) {
          app.current_view = hash_value;
        }
      }
    </script>
    <script src="components/particles.js"></script>
  </body>
</html>
